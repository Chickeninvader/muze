{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this challenge, we are tasked with the development of AI systems capable of receiving textual descriptions as input and generating high-quality audio wave files as output. These AI systems will craft customized background music, considering various elements such as melody, hits, styles, and more to evoke the intended emotional and contextual resonance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using example from this website:\n",
    "https://docs.ray.io/en/latest/train/examples/lightning/vicuna_13b_lightning_deepspeed_finetune.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install ray\n",
    "!pip3 install datasets\n",
    "!pip3 install transformer\n",
    "!pip3 install numpy datasets \"transformers>=4.19.1\" \"pytorch_lightning>=1.6.5\"\n",
    "!pip3 install accelerate\n",
    "!pip3 install lightning\n",
    "!pip3 install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import re\n",
    "import ray\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForQuestionAnswering\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "BATCH_SIZE_PER_WORKER = 8\n",
    "MODEL_NAME = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init(\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"datasets==2.13.1\",\n",
    "            \"torch>=1.13.0\",\n",
    "            \"deepspeed==0.9.4\",\n",
    "            \"accelerate>=0.20.3\",\n",
    "            \"transformers==4.30.2\",\n",
    "            \"lightning==2.0.3\",\n",
    "        ],\n",
    "    },\n",
    "    ignore_reinit_error=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dataset from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents a sample in the dataset\n",
    "with open(\"/Users/khoavo2003/Documents/GitHub/muze/new_train.json\", 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# reformat data\n",
    "dict_dataset = {\"description\":[], \"url\": []}\n",
    "for info in data.values():\n",
    "  dict_dataset['description'].append(info['description'])\n",
    "  dict_dataset['url'].append(info['url'])\n",
    "\n",
    "# Create a datasets.Dataset instance\n",
    "# You can also specify additional metadata such as features and split\n",
    "my_dataset = Dataset.from_dict(dict_dataset, split='train')\n",
    "\n",
    "# Save the dataset to a file (optional)\n",
    "# dataset_dict.save_to_disk(\"my_dataset\")\n",
    "\n",
    "# Load the dataset from the saved file\n",
    "# loaded_dataset = DatasetDict.load_from_disk(\"my_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['description', 'url'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess input and label to appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: include the tokenizer for input and output, and code to get url\n",
    "tokenizer_input = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer_output = AutoTokenizer.from_pretrained\n",
    "def preprocess_input_output(input: str, output: str):\n",
    "  '''\n",
    "  function to preprocess input based on input and output tokenizer\n",
    "  args:\n",
    "    - input(str): string need to encode (description in this case)\n",
    "    - output(str): url to the music\n",
    "  '''\n",
    "  input_token = tokenizer_input.tokenize(input)\n",
    "  input_preprocess = tokenizer_input.convert_tokens_to_ids(input_token)\n",
    "  #TODO: include code to get data from url, change it to appropriate format, and get preprocess output\n",
    "  output_token = tokenizer_output.tokenize(output)\n",
    "  output_preprocess = tokenizer_output.convert_tokens_to_ids(output_token)\n",
    "  return input_preprocess, output_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = my_dataset.map(\n",
    "    lambda example: preprocess_input_output(example['description'], example['url']),\n",
    "    batched=True,\n",
    "    remove_columns=['description', 'url'],  # Remove the original columns\n",
    ")\n",
    "# TODO: Rename columns to 'input_ids' and 'labels'\n",
    "processed_dataset = processed_dataset.rename_column(\"0\", \"input_ids\")\n",
    "processed_dataset = processed_dataset.rename_column(\"1\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = processed_dataset.train_test_split(train_size=0.8, seed=20)\n",
    "processed_dataset[\"validation\"] = processed_dataset.pop(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train and evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change audio data into format that can be used to train and evaluate the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize music \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " define a collate function that will apply the correct amount of padding to the items of the dataset we want to batch together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer_input, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"marian-finetuned-kde4-en-to-fr\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    processed_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator, num_workers=4, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    processed_dataset[\"validation\"], batch_size=8, collate_fn=data_collator, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSpeed Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"result\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"valid\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another code for training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "            )\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(generated_tokens)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=\"huggingface-course/codeparrot-ds\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ray\n",
    "import lightning.pytorch as pl\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import (\n",
    "    init_empty_weights,\n",
    "    infer_auto_device_map,\n",
    "    load_checkpoint_and_dispatch,\n",
    ")\n",
    "\n",
    "# Initialize a model on meta device\n",
    "with init_empty_weights():\n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    meta_model = AutoModelForCausalLM.from_config(config)\n",
    "meta_model.tie_weights()\n",
    "\n",
    "# Define the device mapping\n",
    "device_map = infer_auto_device_map(\n",
    "    meta_model,\n",
    "    max_memory={0: \"15GB\", \"cpu\": \"60GB\"},\n",
    "    no_split_module_classes=[\"LlamaDecoderLayer\"],\n",
    ")\n",
    "\n",
    "# Load the model parameters\n",
    "model = load_checkpoint_and_dispatch(\n",
    "    meta_model,\n",
    "    checkpoint=full_model_ckpt_path,\n",
    "    device_map=device_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    device_map=device_map,\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME, padding_side=\"left\", use_fast=False\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strach (for testing code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated tempo: 184.57 beats per minute\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Get the file path to an included audio example\n",
    "filename = \"we_wish_you.mp3\"\n",
    "\n",
    "# Load the audio as a waveform `y`\n",
    "# Store the sampling rate as `sr`\n",
    "y, sr = librosa.load(filename)\n",
    "\n",
    "# Run the default beat tracker\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "# Convert the frame indices of beat events into timestamps\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "\n",
    "# Function to play audio when the button is clicked\n",
    "clear_output(wait=True)  # Clear the previous output, if any\n",
    "display(Audio(y, rate=sr))  # Play the audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2023/09/text-to-sound-train-your-large-language-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cr37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
